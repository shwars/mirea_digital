{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реляционные СУБД\n",
    "\n",
    "Вернёмся к проблеме извлечения знаний из датасета коронавирусных статей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('c:/users/dmitr/downloads/metadata.csv.zip')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам бы хотелось уметь быстро находить статьи, в которых упоминаются те или иные лекарства. Для полного извлечение информации о лекарствах, используем нейросетевой подход к извлечению именованных сущностей. Воспользуемся идеей из [этой статьи](https://gbnegrini.com/post/biomedical-text-nlp-scispacy-named-entity-recognition-medical-records/). \n",
    "\n",
    "Для начала установим библиотеку **spacy** и специальный модуль для извлечения из текста названий химических веществ и медицинских диагнозов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее загружаем модуль `en_ner_bc5cdr_md` для извлечения сущностей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_ner_bc5cdr_md\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем в пару строк кода извлечь необходимые сущности из текста. Сделаем это на основе первого абстракта из нашей базы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(df.iloc[1]['abstract'])\n",
    "displacy.render(doc,style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in doc.ents:\n",
    "    print(e.label_,e.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлечем все сущности из всех абстрактов. Заодно также обработаем поле **авторы**, поскольку в этом поле обысно содержится несколько фамилий. Выделим их в отдельную таблицу с авторами.\n",
    "\n",
    "В результате получим словари с авторами и сущностями, которые ссылаются (содержат номера индексов) на те статьи, в которых они содержатся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = {}\n",
    "authors = {}\n",
    "for id,abs,auth in zip(df.index,tqdm(df[\"abstract\"]),df['authors']):\n",
    "    if abs is np.nan or auth is np.nan:\n",
    "        continue\n",
    "    for a in auth.split(';'):\n",
    "        aa = a.strip()\n",
    "        if aa in authors.keys():\n",
    "            authors[aa].add(id)\n",
    "        else:\n",
    "            authors[aa] = set([id])\n",
    "    doc = nlp(abs)\n",
    "    for e in doc.ents:\n",
    "        if e.label_ not in ents.keys():\n",
    "            ents[e.label_] = {}\n",
    "        if e.text not in ents[e.label_].keys():\n",
    "            ents[e.label_][e.text] = set([id])\n",
    "        else:\n",
    "            ents[e.label_][e.text].add(id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На всякий случай запишем данные на диск, чтобы в дальнейшем их можно было легко загрузить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class SetEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "with open('authors.json','w',encoding='utf-8') as f:\n",
    "    json.dump(authors,f,ensure_ascii=False,cls=SetEncoder)\n",
    "\n",
    "with open('ents.json','w',encoding='utf-8') as f:\n",
    "    json.dump(ents,f,ensure_ascii=False,cls=SetEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для загрузки данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "authors = json.load(open('authors.json'))\n",
    "ents = json.load(open('ents.json'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разместим данные об авторах, заболеваниях и веществах в отдельных таблицах (датафреймах), а также создадим датафреймы для связи между сущностями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors = pd.DataFrame({ \"author_name\" : authors.keys() })\n",
    "df_diseases = pd.DataFrame({ \"disease\" : ents['DISEASE'].keys() })\n",
    "df_chems = pd.DataFrame({ \"chem\" : ents['CHEMICAL'].keys() })\n",
    "\n",
    "def create_link(df,d):\n",
    "    res = []\n",
    "    for i,x in df.iterrows():\n",
    "        for t in d[x[0]]:\n",
    "            res.append((i,t))\n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "lnk_disease = create_link(df_diseases,ents['DISEASE']).rename(columns={ 0 : 'disease', 1 : 'publication'})\n",
    "lnk_chem = create_link(df_chems,ents['CHEMICAL']).rename(columns={ 0 : 'chem', 1 : 'publication'})\n",
    "lnk_author = create_link(df_authors,authors).rename(columns={ 0 : 'author', 1 : 'publication'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из исходного датафрейма оставим только те поля, которые на вошли в наши дополнительные таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pubs=df[['title','abstract','publish_time']].copy()\n",
    "df_pubs['publish_time'] = pd.to_datetime(df_pubs['publish_time'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом мы получили представление наших исходных данных, которое состоит из нескольких реляционных таблиц:\n",
    "* Публикации\n",
    "* Авторы + таблица связей\n",
    "* Вещества + таблица связей\n",
    "* Диагнозы + таблица связей\n",
    "\n",
    "Теперь мы можем делать к этом модели эффективные запросы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = df_chems[df_chems['chem']=='chloroquine'].index[0]\n",
    "lnk_chem[lnk_chem['chem']==i].join(df_pubs,on='publication')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или восстанавливать исходное представление с помощью соединения таблиц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pubs.join(lnk_chem.set_index('publication')).join(df_chems,on='chem',lsuffix=\"l_\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для более полного анализа попробуем также извлечь из текста дозы медикаментов. Это делается с помощью комбинации извлечения сущностей (как выше) и регулярных выражений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "pattern = [{'ENT_TYPE':'CHEMICAL'}, {'LIKE_NUM': True}, {'IS_ASCII': True}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"DRUG_DOSE\", [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_to_idx = { n.lower() : id for id,n in zip(df_chems.index,df_chems['chem'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "res = []\n",
    "for id,abs in zip(df.index,tqdm(df['abstract'])):\n",
    "    if abs is np.nan:\n",
    "        continue\n",
    "    doc = nlp(abs)\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "        span = doc[start:end]  # the matched span\n",
    "        #print(f\"{doc[start]} -> {doc[start+1]} -> {doc[start+2]}\")\n",
    "        #print(string_id, start, end, span.text)\n",
    "        med = doc[start].text\n",
    "        try:\n",
    "            i = chem_to_idx.get(med.lower(),-1)\n",
    "            if i>=0:\n",
    "                res.append((id,i,doc[start+1],doc[start+2]))\n",
    "        except:\n",
    "            print(f\"{doc[start]} -> {doc[start+1]} -> {doc[start+2]}\")\n",
    "            pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем данные на всякий случай на диск:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('doses.json','w',encoding='utf-8') as f:\n",
    "    json.dump(res,f,ensure_ascii=False,default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = json.load(open('doses.json'))\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doses = pd.DataFrame(r).rename(columns={ 0 : \"publication\", 1 : \"chem\", 2 : \"dose\", 3 : \"unit\" })\n",
    "df_doses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = df_chems[df_chems['chem']=='chloroquine'].index[0]\n",
    "\n",
    "tdf = df_doses.join(df_chems,on='chem',lsuffix=\"_\")\n",
    "tdf[tdf[\"chem\"].apply(lambda x: len(x)>5)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь загрузим все эти данные в таблицы PostgreSQL. Для этого установим библиотеку для подключения к СУБД:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install psycopg[binary]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем по-очереди все таблицы и загружаем туда данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "\n",
    "with psycopg.connect('dbname=cord user=postgres password=p@ssw0rd') as conn:\n",
    "    try:\n",
    "        conn.execute(\"CREATE TABLE AUTHORS (ID INT PRIMARY KEY, AUTHOR_NAME TEXT NOT NULL)\")\n",
    "        for i,x in zip(df_authors.index,df_authors['author_name']):\n",
    "            conn.execute('INSERT INTO AUTHORS (ID, AUTHOR_NAME) VALUES (%s,%s)',(i,x))\n",
    "        conn.commit()\n",
    "    except:\n",
    "        conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "\n",
    "conn = psycopg.connect('dbname=cord user=postgres password=p@ssw0rd')\n",
    "conn.execute(\"CREATE TABLE AUTHORS (ID INT PRIMARY KEY, AUTHOR_NAME TEXT NOT NULL)\")\n",
    "for i,x in zip(df_authors.index,df_authors['author_name']):\n",
    "    conn.execute('INSERT INTO AUTHORS (ID, AUTHOR_NAME) VALUES (%s,%s)',(i,x))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"CREATE TABLE CHEMS (ID INT PRIMARY KEY, CHEM_NAME TEXT NOT NULL)\")\n",
    "for i,x in zip(df_chems.index,df_chems['chem']):\n",
    "    conn.execute('INSERT INTO CHEMS (ID, CHEM_NAME) VALUES (%s,%s)',(i,x))\n",
    "conn.execute(\"CREATE TABLE DISEASES (ID INT PRIMARY KEY, DISEASE_NAME TEXT NOT NULL)\")\n",
    "for i,x in zip(df_diseases.index,df_diseases['disease']):\n",
    "    conn.execute('INSERT INTO DISEASES (ID, DISEASE_NAME) VALUES (%s,%s)',(i,x))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "  CREATE TABLE PUBLICATIONS (\n",
    "    ID INT PRIMARY KEY,\n",
    "    TITLE TEXT NOT NULL,\n",
    "    ABSTRACT TEXT NOT NULL,\n",
    "    PUBLISH_TIME DATE\n",
    "    )\n",
    "\"\"\")\n",
    "for i,x in df_pubs.iterrows():\n",
    "  conn.execute(\"INSERT INTO PUBLICATIONS (ID,TITLE,ABSTRACT,PUBLISH_TIME) VALUES (%s,%s,%s,%s)\",\n",
    "               (i,x['title'],x['abstract'],x['publish_time']))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"CREATE TABLE LDISEASE (DISEASE_ID INT, PUB_ID INT)\")\n",
    "for _,x in lnk_disease.iterrows():\n",
    "    conn.execute(\"INSERT INTO LDISEASE (DISEASE_ID, PUB_ID) VALUES (%s,%s)\",\n",
    "                 (int(x['disease']),int(x['publication'])))\n",
    "conn.execute(\"CREATE TABLE LCHEM (CHEM_ID INT, PUB_ID INT)\")\n",
    "for _,x in lnk_chem.iterrows():\n",
    "    conn.execute(\"INSERT INTO LCHEM (CHEM_ID, PUB_ID) VALUES (%s,%s)\",\n",
    "                 (int(x['chem']),int(x['publication'])))\n",
    "conn.execute(\"CREATE TABLE LAUTHOR (AUTHOR_ID INT, PUB_ID INT)\")\n",
    "for _,x in lnk_author.iterrows():\n",
    "    conn.execute(\"INSERT INTO LAUTHOR (AUTHOR_ID, PUB_ID) VALUES (%s,%s)\",\n",
    "                 (int(x['author']),int(x['publication'])))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"CREATE TABLE LCHEMDOSE (CHEM_ID INT, PUB_ID INT, DOSE TEXT, UNIT TEXT)\")\n",
    "for _,x in df_doses.iterrows():\n",
    "    if len(x['dose'])>4:\n",
    "        conn.execute(\"INSERT INTO LCHEMDOSE (CHEM_ID, PUB_ID, DOSE, UNIT) VALUES (%s,%s,%s,%s)\",\n",
    "                    (int(x['chem']),int(x['publication']),x['dose'],x['unit']))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем делать произвольные SQL-запросы к нашей базе данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = conn.execute(\"\"\"\n",
    "select c.chem_name, d.dose, d.unit, p.title \n",
    "from publications p \n",
    "join lchemdose d on p.id=d.pub_id\n",
    "join chems c on d.chem_id=c.id\n",
    "where length(c.chem_name)>4\n",
    "\"\"\")\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
